{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b0975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] DATA_DIR: D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\workflow\\data\n",
      "[INFO] CSV_CLEAN: D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\workflow\\data\\images_clean.csv\n",
      "[INFO] CROP_DIR: D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\workflow\\data\\cropped_images\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 003_extract_features.ipynb\n",
    "# Step 3: Extract CNN features from cropped images\n",
    "# ç¬¬3æ­¥ï¼šä»è£å‰ªåçš„å›¾ç‰‡ä¸­æå–CNNç‰¹å¾å‘é‡\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === è·¯å¾„é…ç½® Path Config ===\n",
    "DATA_DIR  = r\"D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\workflow\\data\"\n",
    "CSV_CLEAN = os.path.join(DATA_DIR, \"images_clean.csv\")      # ç¬¬00æ­¥è¾“å‡ºçš„CSV\n",
    "IMG_ROOT  = os.path.join(DATA_DIR, \"img\")                   # åŸå›¾ç›®å½•\n",
    "CROP_DIR  = os.path.join(DATA_DIR, \"cropped_images\")        # ç¬¬02æ­¥è¾“å‡ºçš„è£å‰ªå›¾ç›®å½•\n",
    "\n",
    "# === è¾“å‡ºæ–‡ä»¶ Output Paths ===\n",
    "OUT_FEAT  = os.path.join(DATA_DIR, \"features.npy\")          # ç‰¹å¾æ–‡ä»¶\n",
    "OUT_KEYS  = os.path.join(DATA_DIR, \"keys.csv\")              # å›¾ç‰‡å¯¹åº”ä¿¡æ¯\n",
    "\n",
    "# === æ¨¡å‹å‚æ•° Model Parameters ===\n",
    "MODEL_NAME   = \"resnet18\"           # 'resnet50' or 'mobilenet_v3_large'\n",
    "IMAGE_SIZE   = 224\n",
    "BATCH_GPU    = 64\n",
    "BATCH_CPU    = 16\n",
    "NUM_WORKERS  = 0                    # Windows å»ºè®®è®¾ä¸º 0ï¼›è‹¥ç¨³å®šå¯è°ƒä¸º 2/4\n",
    "SKIP_TRAIN   = True                 # Trueï¼šä»…æå– query + gallery\n",
    "ITEM_DEDUP   = False                # Trueï¼šæ¯ç±»ä»…ä¿ç•™ä¸€å¼ å›¾\n",
    "DRY_RUN_N    = None                 # è®¾ä¸º 500 å¯å¿«é€Ÿæµ‹è¯•æµç¨‹ï¼›None = å…¨é‡\n",
    "\n",
    "print(f\"[INFO] DATA_DIR: {DATA_DIR}\")\n",
    "print(f\"[INFO] CSV_CLEAN: {CSV_CLEAN}\")\n",
    "print(f\"[INFO] CROP_DIR: {CROP_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45eadf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total usable images: 52712\n",
      "After filtering query/gallery: 26830 {'query': 14218, 'gallery': 12612}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>eval_split</th>\n",
       "      <th>item_id_eval</th>\n",
       "      <th>item_id</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>image_abs</th>\n",
       "      <th>cropped_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WOMEN/Blouses_Shirts/id_00000001/02_1_front.jpg</td>\n",
       "      <td>gallery</td>\n",
       "      <td>id_00000001</td>\n",
       "      <td>id_00000001</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>208</td>\n",
       "      <td>235</td>\n",
       "      <td>D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\wo...</td>\n",
       "      <td>D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WOMEN/Blouses_Shirts/id_00000001/02_2_side.jpg</td>\n",
       "      <td>query</td>\n",
       "      <td>id_00000001</td>\n",
       "      <td>id_00000001</td>\n",
       "      <td>119</td>\n",
       "      <td>48</td>\n",
       "      <td>136</td>\n",
       "      <td>234</td>\n",
       "      <td>D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\wo...</td>\n",
       "      <td>D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WOMEN/Blouses_Shirts/id_00000001/02_3_back.jpg</td>\n",
       "      <td>gallery</td>\n",
       "      <td>id_00000001</td>\n",
       "      <td>id_00000001</td>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "      <td>213</td>\n",
       "      <td>240</td>\n",
       "      <td>D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\wo...</td>\n",
       "      <td>D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        image_path eval_split item_id_eval  \\\n",
       "0  WOMEN/Blouses_Shirts/id_00000001/02_1_front.jpg    gallery  id_00000001   \n",
       "1   WOMEN/Blouses_Shirts/id_00000001/02_2_side.jpg      query  id_00000001   \n",
       "2   WOMEN/Blouses_Shirts/id_00000001/02_3_back.jpg    gallery  id_00000001   \n",
       "\n",
       "       item_id   x1  y1   x2   y2  \\\n",
       "0  id_00000001   50  49  208  235   \n",
       "1  id_00000001  119  48  136  234   \n",
       "2  id_00000001   50  42  213  240   \n",
       "\n",
       "                                           image_abs  \\\n",
       "0  D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\wo...   \n",
       "1  D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\wo...   \n",
       "2  D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\wo...   \n",
       "\n",
       "                                         cropped_abs  \n",
       "0  D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\wo...  \n",
       "1  D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\wo...  \n",
       "2  D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\wo...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Load cleaned CSV and point to cropped image paths\n",
    "# è¯»å–æ¸…æ´—åçš„CSVï¼Œå¹¶å®šä½åˆ°è£å‰ªå›¾åƒ\n",
    "# ============================================================\n",
    "\n",
    "df = pd.read_csv(CSV_CLEAN)\n",
    "\n",
    "# æ‹¼æ¥ç»å¯¹è·¯å¾„ Absolute path from relative path\n",
    "def to_abs_from_root(rel):\n",
    "    p = str(rel).replace(\"\\\\\", \"/\")\n",
    "    return os.path.join(IMG_ROOT, p)\n",
    "\n",
    "df[\"image_abs\"] = df[\"image_path\"].apply(to_abs_from_root)\n",
    "\n",
    "# å°†åŸå›¾è·¯å¾„æ˜ å°„ä¸ºè£å‰ªå›¾è·¯å¾„\n",
    "rel_paths = df[\"image_abs\"].apply(lambda p: os.path.relpath(p, IMG_ROOT))\n",
    "df[\"cropped_abs\"] = rel_paths.apply(lambda r: os.path.join(CROP_DIR, r))\n",
    "\n",
    "# ä»…ä¿ç•™å­˜åœ¨çš„å›¾åƒ\n",
    "df = df[df[\"cropped_abs\"].apply(os.path.exists)].reset_index(drop=True)\n",
    "print(f\"âœ… Total usable images: {len(df)}\")\n",
    "\n",
    "# è‹¥åªæå– query + gallery\n",
    "if SKIP_TRAIN:\n",
    "    df = df[df[\"eval_split\"].isin([\"query\", \"gallery\"])].reset_index(drop=True)\n",
    "    print(\"After filtering query/gallery:\", len(df), df[\"eval_split\"].value_counts().to_dict())\n",
    "\n",
    "# è‹¥æ¯ä¸ªitemä»…ä¿ç•™ä¸€å¼ \n",
    "if ITEM_DEDUP:\n",
    "    df = df.sort_values(\"image_path\").drop_duplicates([\"item_id\",\"eval_split\"]).reset_index(drop=True)\n",
    "    print(\"After dedup:\", len(df))\n",
    "\n",
    "# å¿«é€Ÿæµ‹è¯•æ¨¡å¼\n",
    "if DRY_RUN_N:\n",
    "    df = df.sample(min(DRY_RUN_N, len(df)), random_state=42).reset_index(drop=True)\n",
    "    print(\"Dry run:\", len(df))\n",
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87fce61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ–¥ï¸ Running on device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Load pretrained CNN (ResNet50 / MobileNet)\n",
    "# è½½å…¥é¢„è®­ç»ƒæ¨¡å‹\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸ–¥ï¸ Running on device: {device}\")\n",
    "\n",
    "if MODEL_NAME == \"resnet50\":\n",
    "    model = torchvision.models.resnet50(\n",
    "        weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V2\n",
    "    )\n",
    "    model.fc = torch.nn.Identity()  # ç§»é™¤æœ€ååˆ†ç±»å±‚\n",
    "    FEAT_DIM = 2048\n",
    "\n",
    "elif MODEL_NAME == \"resnet18\":\n",
    "    model = torchvision.models.resnet18(\n",
    "        weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1\n",
    "    )\n",
    "    model.fc = torch.nn.Identity()  # åŒæ ·ç§»é™¤åˆ†ç±»å±‚ï¼Œå–å€’æ•°ç¬¬äºŒå±‚ç‰¹å¾\n",
    "    FEAT_DIM = 512   # ResNet18 çš„ç‰¹å¾ç»´åº¦æ˜¯ 512\n",
    "\n",
    "elif MODEL_NAME == \"mobilenet_v3_large\":\n",
    "    model = torchvision.models.mobilenet_v3_large(\n",
    "        weights=torchvision.models.MobileNet_V3_Large_Weights.IMAGENET1K_V2\n",
    "    )\n",
    "    model.classifier = torch.nn.Identity()\n",
    "    FEAT_DIM = 960\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported MODEL_NAME: {MODEL_NAME}\")\n",
    "\n",
    "\n",
    "model.eval().to(device)\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba83bb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataloader ready: 1677 batches\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Define dataset and dataloader\n",
    "# å®šä¹‰æ•°æ®åŠ è½½å™¨\n",
    "# ============================================================\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CroppedDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        r = self.df.iloc[idx]\n",
    "        img = Image.open(r[\"cropped_abs\"]).convert(\"RGB\")\n",
    "        x = self.transform(img)\n",
    "        return x, r[\"image_path\"], r[\"item_id\"], r[\"eval_split\"]\n",
    "\n",
    "batch_size = BATCH_GPU if device == \"cuda\" else BATCH_CPU\n",
    "dl = DataLoader(\n",
    "    CroppedDataset(df, transform),\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=(device==\"cuda\")\n",
    ")\n",
    "print(f\"âœ… Dataloader ready: {len(dl)} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5dcaa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract(resnet50,224):   0%|          | 0/1677 [00:00<?, ?it/s]C:\\Users\\Icey\\AppData\\Local\\Temp\\ipykernel_6716\\4006215002.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device == 'cuda')):\n",
      "Extract(resnet50,224): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1677/1677 [44:22<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved features to D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\workflow\\data\\features.npy (shape=(26830, 2048))\n",
      "âœ… Saved keys to D:\\Icey\\tcd\\notebooks\\dMining\\Group Project\\workflow\\data\\keys.csv (rows=26830)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Forward pass and save features\n",
    "# æ‰¹é‡æå–ç‰¹å¾å¹¶ä¿å­˜ç»“æœ\n",
    "# ============================================================\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "torch.set_grad_enabled(False)\n",
    "if device == \"cuda\":\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "feats, keys = [], []\n",
    "desc = f\"Extract({MODEL_NAME},{IMAGE_SIZE})\"\n",
    "\n",
    "for xb, img_paths, item_ids, splits in tqdm(dl, total=len(dl), desc=desc):\n",
    "    xb = xb.to(device, non_blocking=True)\n",
    "    with torch.cuda.amp.autocast(enabled=(device == 'cuda')):\n",
    "        fb = model(xb)\n",
    "        if fb.ndim == 4:  # è‹¥è¾“å‡ºç»´åº¦ä¸º [B,C,1,1]\n",
    "            fb = torch.flatten(fb, 1)\n",
    "        fb = fb.detach().cpu().numpy()\n",
    "    # L2 normalization\n",
    "    fb = fb / (np.linalg.norm(fb, axis=1, keepdims=True) + 1e-9)\n",
    "    feats.append(fb)\n",
    "    keys.extend(zip(img_paths, item_ids, splits))\n",
    "\n",
    "feats = np.vstack(feats).astype(\"float32\")\n",
    "keys_df = pd.DataFrame(keys, columns=[\"image_path\",\"item_id\",\"eval_split\"])\n",
    "\n",
    "# === Save ===\n",
    "np.save(OUT_FEAT, feats)\n",
    "keys_df.to_csv(OUT_KEYS, index=False)\n",
    "print(f\"âœ… Saved features to {OUT_FEAT} (shape={feats.shape})\")\n",
    "print(f\"âœ… Saved keys to {OUT_KEYS} (rows={len(keys_df)})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
